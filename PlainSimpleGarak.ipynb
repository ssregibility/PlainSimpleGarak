{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlainSimpleGarak.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOsnqr6kCWmk"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")\r\n",
        "HOME = 'drive/MyDrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTjqtb-uCWuJ"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "import random\r\n",
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brc2YaVkCW0X"
      },
      "source": [
        "dataset_quotes = []\r\n",
        "\r\n",
        "import os\r\n",
        "with open(\"drive/MyDrive/Data/PlainSimpleGarak-data.txt\", 'r') as f: # open in readonly mode\r\n",
        "  while True:\r\n",
        "    line = f.readline().strip()\r\n",
        "    if line == '':\r\n",
        "        break\r\n",
        "    else:\r\n",
        "      dataset_quotes.append(line)\r\n",
        "\r\n",
        "dataset_startwords = []\r\n",
        "for s in dataset_quotes:\r\n",
        "  dataset_startwords.append(s.split()[0].lower())\r\n",
        "\r\n",
        "dataset_raw = pd.read_csv('drive/MyDrive/Data/quotes.csv', error_bad_lines=False, engine='python')\r\n",
        "\r\n",
        "dataset_quotes_nonascii = list(dataset_raw[\"Quote\"] )\r\n",
        "\r\n",
        "for s in dataset_quotes_nonascii:\r\n",
        "  if (len(s) == len(s.encode())):\r\n",
        "    if (\"$\" not in s and \"&\" not in s):\r\n",
        "      dataset_quotes.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzrtEhX9CW7z"
      },
      "source": [
        "def preprocess_txt(dataset_quotes, appende=True):\r\n",
        "  for i in range(len(dataset_quotes)):\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('\\t', ' ')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('--', ' ')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(' - ', ' ')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('%', ' percent')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('[', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(']', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(':', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(';', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('?', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('#', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('!', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('/', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('.', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(',', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('(', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(')', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('*', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('+', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('\\\"', '')\r\n",
        "    #dataset_quotes[i] = dataset_quotes[i].replace('\\'', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].lower()\r\n",
        "    if (appende == True):\r\n",
        "      dataset_quotes[i] = dataset_quotes[i] + \" <END>\"\r\n",
        "\r\n",
        "preprocess_txt(dataset_quotes)\r\n",
        "preprocess_txt(dataset_startwords, False)\r\n",
        "\r\n",
        "#dataset_quotes.sort()\r\n",
        "dataset_startwords = list(set(dataset_startwords))\r\n",
        "#dataset_startwords.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djk2Wm4ECXNX"
      },
      "source": [
        "def encode(string, word2index):\r\n",
        "  return torch.LongTensor([[word2index[wd] for wd in string.split()]])\r\n",
        "\r\n",
        "def decode(vec, index2word):\r\n",
        "  return [index2word.get(x) for x in vec]\r\n",
        "\r\n",
        "class Dataset(torch.utils.data.Dataset):\r\n",
        "  def __init__(self, txt, seq_len, word2index):\r\n",
        "    self.encoded = [word2index[wd] for wd in txt]\r\n",
        "    self.seq_len = seq_len\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.encoded) - self.seq_len\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    return ( torch.tensor(self.encoded[index:index+self.seq_len]), torch.tensor(self.encoded[index+1:index+self.seq_len+1]) )\r\n",
        "\r\n",
        "txt_quotes = \"\"\r\n",
        "for s in dataset_quotes:\r\n",
        "  txt_quotes = txt_quotes + \" \" + s\r\n",
        "txt_quotes = txt_quotes.split()\r\n",
        "\r\n",
        "list_words = list(set(txt_quotes))\r\n",
        "list_words.sort()\r\n",
        "\r\n",
        "word2index = {tkn: i for i, tkn in enumerate(list_words, 1)}\r\n",
        "word2index['<UNKNOWN>']=0\r\n",
        "index2word = {v: k for k, v in word2index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-aKVYk9VbNf"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "  def __init__(self, embed_size, input_dim, hidden_dim, batch_first=True, n_layers = 1, dropout = 0.2):\r\n",
        "    super(Net, self).__init__()\r\n",
        "\r\n",
        "    self.n_layers = n_layers #unused\r\n",
        "    self.hidden_dim = hidden_dim\r\n",
        "\r\n",
        "    self.embedding_layer = nn.Embedding(num_embeddings=embed_size, embedding_dim=input_dim)\r\n",
        "    #1\r\n",
        "    self.rnn_layer = nn.GRU(input_dim, hidden_dim, batch_first=batch_first, num_layers=n_layers, dropout=dropout)\r\n",
        "    #self.dropout = nn.Dropout(0.4)\r\n",
        "    self.linear = nn.Linear(hidden_dim, embed_size)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    output = self.embedding_layer(x)\r\n",
        "\r\n",
        "    output, hidden = self.rnn_layer(output)\r\n",
        "    #output = self.dropout(output)\r\n",
        "    output = self.linear(output)\r\n",
        "\r\n",
        "    return output\r\n",
        "    #return output.view(-1, output.size(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTuY0mFsPGJM"
      },
      "source": [
        "vocab_size = len(word2index)\r\n",
        "input_size =  128\r\n",
        "hidden_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkIrDNq1PGbB"
      },
      "source": [
        "model1 = Net(vocab_size, input_size, hidden_size, batch_first=True)\r\n",
        "model1.cuda()\r\n",
        "model2 = Net(vocab_size, input_size, hidden_size, batch_first=True)\r\n",
        "model2.cuda()\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer1 = optim.Adam(params=model1.parameters())\r\n",
        "optimizer2 = optim.Adam(params=model2.parameters())\r\n",
        "\r\n",
        "dataset = Dataset(txt_quotes, 10, word2index)\r\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3i1JU-yCaUM"
      },
      "source": [
        "epoch_to_load = 0\r\n",
        "\r\n",
        "if epoch_to_load != 0:\r\n",
        "  x = torch.load(\"drive/MyDrive/Data/Checkpoint1/\" + \"CPOINT-\" + str(epoch_to_load))\r\n",
        "  model1.load_state_dict(x['model1_state_dict'])\r\n",
        "  model2.load_state_dict(x['model2_state_dict'])\r\n",
        "  optimizer1.load_state_dict(x['optimizer1_state_dict'])\r\n",
        "  optimizer2.load_state_dict(x['optimizer2_state_dict'])\r\n",
        "  epoch_to_load = epoch_to_load + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ifOlYWPGhV"
      },
      "source": [
        "def test_model(model, word2index, index2word, string=\"\", maxlen=25, verbose=False):\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  eval_input = encode(string, word2index).cuda()\r\n",
        "  print(\"INITIAL INPUT: \" + string)\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "    print(\"---\")\r\n",
        "\r\n",
        "  for i in range(maxlen):\r\n",
        "    output = model(eval_input)\r\n",
        "    pred = output.softmax(-1).argmax(-1)\r\n",
        "\r\n",
        "    if verbose:\r\n",
        "      print(\"INPUT: \" + \" \".join( decode(eval_input.tolist()[0],index2word)))\r\n",
        "      print(\"OUTPUT: \" + \" \".join( decode(pred[0].tolist(), index2word)))\r\n",
        "\r\n",
        "    eval_input = torch.cat((eval_input,pred[:,-1].unsqueeze(0)), 1)\r\n",
        "\r\n",
        "    if word2index['<END>'] in eval_input:\r\n",
        "      break\r\n",
        "\r\n",
        "  print(\"GENERATED SEQUENCE: \" + \" \".join( decode(eval_input.tolist()[0],index2word)))\r\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfHtYA-yPGnY"
      },
      "source": [
        "for epoch in range(epoch_to_load, 1001):\r\n",
        "  model1.train()\r\n",
        "  model2.train()\r\n",
        "\r\n",
        "  for batch, (input, target) in enumerate(dataloader):\r\n",
        "    optimizer1.zero_grad()\r\n",
        "    output1 = model1(input.cuda())\r\n",
        "    loss1 = criterion(output1.transpose(1, 2), target.cuda())\r\n",
        "    loss1.backward()\r\n",
        "    optimizer1.step()\r\n",
        "\r\n",
        "    optimizer2.zero_grad()\r\n",
        "    output2 = model2(input.cuda())\r\n",
        "    loss2 = criterion(output2.transpose(1, 2), target.cuda())\r\n",
        "    loss2.backward()\r\n",
        "    optimizer2.step()\r\n",
        "\r\n",
        "  model1.eval()\r\n",
        "  model2.eval()\r\n",
        "  print(\"Epoch {:02d} / 1001 Loss1 {:.4f} Loss2 {:.4f}\".format(epoch+1, loss1, loss2))\r\n",
        "  \r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  print(\"TARGET: \" + \" \".join( decode(target[0].tolist(),index2word)))\r\n",
        "  print(\"INPUT: \" + \" \".join( decode(input[0].tolist(),index2word)))\r\n",
        "  pred = output1[0].softmax(-1).argmax(-1)\r\n",
        "  print(\"PREDICTION: \" + \" \".join(decode(pred.tolist(),index2word)))\r\n",
        "\r\n",
        "  print(\"---------------------------------------------------------------------------\")\r\n",
        "\r\n",
        "  print(\"TARGET: \" + \" \".join( decode(target[0].tolist(),index2word)))\r\n",
        "  print(\"INPUT: \" + \" \".join( decode(input[0].tolist(),index2word)))\r\n",
        "  pred = output2[0].softmax(-1).argmax(-1)\r\n",
        "  print(\"PREDICTION: \" + \" \".join(decode(pred.tolist(),index2word)))\r\n",
        "\r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  randword = dataset_startwords[random.randrange(0,len(dataset_startwords))]\r\n",
        "\r\n",
        "  test_model(model1, word2index, index2word, randword)\r\n",
        "  test_model(model1, word2index, index2word, \"i am plain simple garak \" + randword)\r\n",
        "\r\n",
        "  test_model(model2, word2index, index2word, randword)\r\n",
        "  test_model(model2, word2index, index2word, \"i am plain simple garak \" + randword)\r\n",
        "\r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  if (epoch % 5 == 0):\r\n",
        "    #torch.save(model.state_dict(), \"drive/MyDrive/Data/\" + \"Checkpoint-\" + str(epoch) )\r\n",
        "    torch.save(\r\n",
        "        {'model1_state_dict': model1.state_dict(),\r\n",
        "         'model2_state_dict': model2.state_dict(),\r\n",
        "         'optimizer1_state_dict': optimizer1.state_dict(),\r\n",
        "         'optimizer2_state_dict': optimizer2.state_dict(),},\r\n",
        "        'drive/MyDrive/Data/Checkpoint1/' + \"CPOINT-\" + str(epoch)\r\n",
        "               )\r\n",
        "\r\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzkWUg-bLz5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtlJK8P-Mknd"
      },
      "source": [
        "class Net_variant(nn.Module):\r\n",
        "  def __init__(self, embed_size, input_dim, hidden_dim, batch_first=True, n_layers = 1, dropout = 0.2):\r\n",
        "    super(Net_variant, self).__init__()\r\n",
        "\r\n",
        "    self.n_layers = n_layers #unused\r\n",
        "    self.hidden_dim = hidden_dim\r\n",
        "\r\n",
        "    #shared embedding layer\r\n",
        "    self.embedding_layer = nn.Embedding(num_embeddings=embed_size, embedding_dim=input_dim)\r\n",
        "    \r\n",
        "    #1\r\n",
        "    self.rnn_layer1 = nn.GRU(input_dim, hidden_dim, batch_first=batch_first, num_layers=n_layers, dropout=dropout)\r\n",
        "    self.linear1 = nn.Linear(hidden_dim, embed_size)\r\n",
        "\r\n",
        "    #2\r\n",
        "    self.rnn_layer2 = nn.GRU(input_dim, hidden_dim, batch_first=batch_first, num_layers=n_layers, dropout=dropout)\r\n",
        "    self.linear2 = nn.Linear(hidden_dim, embed_size)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    output = self.embedding_layer(x)\r\n",
        "\r\n",
        "    if (random.randrange(2) == 0):\r\n",
        "      output1, hidden1 = self.rnn_layer1(output)\r\n",
        "      output1 = self.linear1(output1)\r\n",
        "      return output1\r\n",
        "    else:\r\n",
        "      output2, hidden2 = self.rnn_layer2(output)\r\n",
        "      output2 = self.linear2(output2)\r\n",
        "      return output2\r\n",
        "\r\n",
        "    #return output\r\n",
        "    #return output.view(-1, output.size(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47r5zdi0NgY7"
      },
      "source": [
        "vocab_size = len(word2index)\r\n",
        "input_size =  128\r\n",
        "hidden_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEkpUobLNiCd"
      },
      "source": [
        "model = Net_variant(vocab_size, input_size, hidden_size, batch_first=True)\r\n",
        "model.cuda()\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(params=model.parameters())\r\n",
        "\r\n",
        "dataset = Dataset(txt_quotes, 10, word2index)\r\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVfnVjN1NiIj"
      },
      "source": [
        "epoch_to_load = 0\r\n",
        "\r\n",
        "if epoch_to_load != 0:\r\n",
        "  x = torch.load(\"drive/MyDrive/Data/Checkpoint1/\" + \"CPOINT-\" + str(epoch_to_load))\r\n",
        "  model.load_state_dict(x['model_state_dict'])\r\n",
        "  optimizer.load_state_dict(x['optimizer_state_dict'])\r\n",
        "  epoch_to_load = epoch_to_load + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdroP3n6NiOe"
      },
      "source": [
        "def test_model(model, word2index, index2word, string=\"\", maxlen=25, verbose=False):\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  eval_input = encode(string, word2index).cuda()\r\n",
        "  print(\"INITIAL INPUT: \" + string)\r\n",
        "\r\n",
        "  if verbose:\r\n",
        "    print(\"---\")\r\n",
        "\r\n",
        "  for i in range(maxlen):\r\n",
        "    output = model(eval_input)\r\n",
        "    pred = output.softmax(-1).argmax(-1)\r\n",
        "\r\n",
        "    if verbose:\r\n",
        "      print(\"INPUT: \" + \" \".join( decode(eval_input.tolist()[0],index2word)))\r\n",
        "      print(\"OUTPUT: \" + \" \".join( decode(pred[0].tolist(), index2word)))\r\n",
        "\r\n",
        "    eval_input = torch.cat((eval_input,pred[:,-1].unsqueeze(0)), 1)\r\n",
        "\r\n",
        "    if word2index['<END>'] in eval_input:\r\n",
        "      break\r\n",
        "\r\n",
        "  print(\"GENERATED SEQUENCE: \" + \" \".join( decode(eval_input.tolist()[0],index2word)))\r\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUpeBOTVNiVP"
      },
      "source": [
        "for epoch in range(epoch_to_load, 1001):\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  for batch, (input, target) in enumerate(dataloader):\r\n",
        "    optimizer.zero_grad()\r\n",
        "    output = model(input.cuda())\r\n",
        "    loss = criterion(output.transpose(1, 2), target.cuda())\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "  print(\"Epoch {:02d} / 1001 Loss {:.4f}\".format(epoch+1, loss))\r\n",
        "  \r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  print(\"TARGET: \" + \" \".join( decode(target[0].tolist(),index2word)))\r\n",
        "  print(\"INPUT: \" + \" \".join( decode(input[0].tolist(),index2word)))\r\n",
        "  pred = output[0].softmax(-1).argmax(-1)\r\n",
        "  print(\"PREDICTION: \" + \" \".join(decode(pred.tolist(),index2word)))\r\n",
        "\r\n",
        "  print(\"---------------------------------------------------------------------------\")\r\n",
        "\r\n",
        "  print(\"TARGET: \" + \" \".join( decode(target[0].tolist(),index2word)))\r\n",
        "  print(\"INPUT: \" + \" \".join( decode(input[0].tolist(),index2word)))\r\n",
        "  pred = output[0].softmax(-1).argmax(-1)\r\n",
        "  print(\"PREDICTION: \" + \" \".join(decode(pred.tolist(),index2word)))\r\n",
        "\r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  randword = dataset_startwords[random.randrange(0,len(dataset_startwords))]\r\n",
        "\r\n",
        "  test_model(model, word2index, index2word, randword)\r\n",
        "  test_model(model, word2index, index2word, randword)\r\n",
        "\r\n",
        "  test_model(model, word2index, index2word, \"i am plain simple garak \" + randword)\r\n",
        "  test_model(model, word2index, index2word, \"i am plain simple garak \" + randword)\r\n",
        "\r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  if (epoch % 5 == 0):\r\n",
        "    #torch.save(model.state_dict(), \"drive/MyDrive/Data/\" + \"Checkpoint-\" + str(epoch) )\r\n",
        "    torch.save(\r\n",
        "        {'model_state_dict': model.state_dict(),\r\n",
        "         'optimizer_state_dict': optimizer.state_dict(),},\r\n",
        "        'drive/MyDrive/Data/Checkpoint1/' + \"CPOINT-\" + str(epoch)\r\n",
        "               )\r\n",
        "\r\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjepplBMNicB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87vuqyKuNiib"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctpq8D20Nisk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIlycosXrBiy"
      },
      "source": [
        "dataset_quotes = []\r\n",
        "with open(\"drive/MyDrive/Data/PlainSimpleGarak-data.txt\", 'r') as f: # open in readonly mode\r\n",
        "  while True:\r\n",
        "    line = f.readline().strip()\r\n",
        "    if line == '':\r\n",
        "        break\r\n",
        "    else:\r\n",
        "      dataset_quotes.append(line)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fc8r-YmrLuN"
      },
      "source": [
        "def preprocess_txt(dataset_quotes, appende=True):\r\n",
        "  for i in range(len(dataset_quotes)):\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('\\t', ' ')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('--', ' ')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(' - ', ' ')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('%', ' percent')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('[', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(']', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(':', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(';', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('?', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('#', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('!', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('/', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('.', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(',', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('(', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace(')', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('*', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('+', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].replace('\\\"', '')\r\n",
        "    #dataset_quotes[i] = dataset_quotes[i].replace('\\'', '')\r\n",
        "    dataset_quotes[i] = dataset_quotes[i].lower()\r\n",
        "    if (appende == True):\r\n",
        "      dataset_quotes[i] = dataset_quotes[i] + \" <END>\"\r\n",
        "\r\n",
        "preprocess_txt(dataset_quotes)\r\n",
        "preprocess_txt(dataset_startwords, False)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqvXMPQ9rNJ9"
      },
      "source": [
        "def encode(string, word2index):\r\n",
        "  return torch.LongTensor([[word2index[wd] for wd in string.split()]])\r\n",
        "\r\n",
        "def decode(vec, index2word):\r\n",
        "  return [index2word.get(x) for x in vec]\r\n",
        "\r\n",
        "class Dataset(torch.utils.data.Dataset):\r\n",
        "  def __init__(self, txt, seq_len, word2index):\r\n",
        "    self.encoded = [word2index[wd] for wd in txt]\r\n",
        "    self.seq_len = seq_len\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.encoded) - self.seq_len\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    return ( torch.tensor(self.encoded[index:index+self.seq_len]), torch.tensor(self.encoded[index+1:index+self.seq_len+1]) )\r\n",
        "\r\n",
        "txt_quotes = \"\"\r\n",
        "for s in dataset_quotes:\r\n",
        "  txt_quotes = txt_quotes + \" \" + s\r\n",
        "txt_quotes = txt_quotes.split()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC-2VTBYrRj8",
        "outputId": "593f4f16-4f8d-4b6a-8f60-e90b7aee44a3"
      },
      "source": [
        "model = Net_variant(vocab_size, input_size, hidden_size, batch_first=True)\r\n",
        "model.cuda()\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\r\n",
        "\r\n",
        "dataset = Dataset(txt_quotes, 15, word2index)\r\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSSMpCPtrYEZ"
      },
      "source": [
        "epoch_to_load = 500\r\n",
        "\r\n",
        "if epoch_to_load != 0:\r\n",
        "  x = torch.load(\"drive/MyDrive/Data/Checkpoint1/\" + \"CPOINTB-\" + str(epoch_to_load))\r\n",
        "  model.load_state_dict(x['model_state_dict'])\r\n",
        "  #optimizer.load_state_dict(x['optimizer_state_dict'])\r\n",
        "  epoch_to_load = epoch_to_load + 1"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMD2J5XPr11k",
        "outputId": "41cb27ee-dbf4-4731-c0e6-87127ede2b19"
      },
      "source": [
        "for epoch in range(epoch_to_load, 2501):\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  for batch, (input, target) in enumerate(dataloader):\r\n",
        "    optimizer.zero_grad()\r\n",
        "    output = model(input.cuda())\r\n",
        "    loss = criterion(output.transpose(1, 2), target.cuda())\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "  print(\"Epoch {:02d} / 2501 Loss {:.4f}\".format(epoch+1, loss))\r\n",
        "  \r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  print(\"TARGET: \" + \" \".join( decode(target[0].tolist(),index2word)))\r\n",
        "  print(\"INPUT: \" + \" \".join( decode(input[0].tolist(),index2word)))\r\n",
        "  pred = output[0].softmax(-1).argmax(-1)\r\n",
        "  print(\"PREDICTION: \" + \" \".join(decode(pred.tolist(),index2word)))\r\n",
        "\r\n",
        "  print(\"---------------------------------------------------------------------------\")\r\n",
        "\r\n",
        "  print(\"TARGET: \" + \" \".join( decode(target[0].tolist(),index2word)))\r\n",
        "  print(\"INPUT: \" + \" \".join( decode(input[0].tolist(),index2word)))\r\n",
        "  pred = output[0].softmax(-1).argmax(-1)\r\n",
        "  print(\"PREDICTION: \" + \" \".join(decode(pred.tolist(),index2word)))\r\n",
        "\r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  randword = dataset_startwords[random.randrange(0,len(dataset_startwords))]\r\n",
        "\r\n",
        "  test_model(model, word2index, index2word, randword)\r\n",
        "  test_model(model, word2index, index2word, randword)\r\n",
        "\r\n",
        "  test_model(model, word2index, index2word, \"i am plain simple garak \" + randword)\r\n",
        "  test_model(model, word2index, index2word, \"i am plain simple garak \" + randword)\r\n",
        "\r\n",
        "  print(\"===========================================================================\")\r\n",
        "\r\n",
        "  if (epoch % 50 == 0):\r\n",
        "    #torch.save(model.state_dict(), \"drive/MyDrive/Data/\" + \"Checkpoint-\" + str(epoch) )\r\n",
        "    torch.save(\r\n",
        "        {'model_state_dict': model.state_dict(),\r\n",
        "         'optimizer_state_dict': optimizer.state_dict(),},\r\n",
        "        'drive/MyDrive/Data/Checkpoint1/' + \"CPOINT_FINETUNE-\" + str(epoch)\r\n",
        "               )\r\n",
        "\r\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 502 / 1001 Loss 0.4525\n",
            "===========================================================================\n",
            "TARGET: thing that is why i prefer the simple straight line simplicity of cutting cloth <END>\n",
            "INPUT: a thing that is why i prefer the simple straight line simplicity of cutting cloth\n",
            "PREDICTION: very that killed why i prefer the simple straight line simplicity of cutting cloth <END>\n",
            "---------------------------------------------------------------------------\n",
            "TARGET: thing that is why i prefer the simple straight line simplicity of cutting cloth <END>\n",
            "INPUT: a thing that is why i prefer the simple straight line simplicity of cutting cloth\n",
            "PREDICTION: very that killed why i prefer the simple straight line simplicity of cutting cloth <END>\n",
            "===========================================================================\n",
            "INITIAL INPUT: neytiri\n",
            "GENERATED SEQUENCE: neytiri calls me skxawng it means moron <END>\n",
            "\n",
            "INITIAL INPUT: neytiri\n",
            "GENERATED SEQUENCE: neytiri calls me skxawng it means moron <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak neytiri\n",
            "GENERATED SEQUENCE: i am plain simple garak neytiri <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak neytiri\n",
            "GENERATED SEQUENCE: i am plain simple garak neytiri <END>\n",
            "\n",
            "===========================================================================\n",
            "\n",
            "Epoch 503 / 1001 Loss 0.4306\n",
            "===========================================================================\n",
            "TARGET: comes down to a question of loyalty yiri had to choose between protecting his brother\n",
            "INPUT: all comes down to a question of loyalty yiri had to choose between protecting his\n",
            "PREDICTION: the down to a question of loyalty yiri had to choose between protecting his brother\n",
            "---------------------------------------------------------------------------\n",
            "TARGET: comes down to a question of loyalty yiri had to choose between protecting his brother\n",
            "INPUT: all comes down to a question of loyalty yiri had to choose between protecting his\n",
            "PREDICTION: the down to a question of loyalty yiri had to choose between protecting his brother\n",
            "===========================================================================\n",
            "INITIAL INPUT: aphrodite\n",
            "GENERATED SEQUENCE: aphrodite is walking through the halls shimmering like a scalpel steinman she calls steinman i have what your looking for just open your eyes and when\n",
            "\n",
            "INITIAL INPUT: aphrodite\n",
            "GENERATED SEQUENCE: aphrodite is walking through the halls shimmering like a scalpel steinman she calls steinman i have what your looking for just open your eyes and when\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak aphrodite\n",
            "GENERATED SEQUENCE: i am plain simple garak aphrodite is walking through the halls shimmering like a scalpel steinman she calls steinman i have what your looking for just open your eyes and when\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak aphrodite\n",
            "GENERATED SEQUENCE: i am plain simple garak aphrodite is walking through the halls shimmering like a scalpel steinman she calls steinman i have what your looking for just open your eyes and when\n",
            "\n",
            "===========================================================================\n",
            "\n",
            "Epoch 504 / 1001 Loss 0.3650\n",
            "===========================================================================\n",
            "TARGET: get them from somewhere else my shop's closed starfleet intelligence is keeping me quite busy\n",
            "INPUT: to get them from somewhere else my shop's closed starfleet intelligence is keeping me quite\n",
            "PREDICTION: be back not somewhere else my shop's closed starfleet intelligence is keeping me quite busy\n",
            "---------------------------------------------------------------------------\n",
            "TARGET: get them from somewhere else my shop's closed starfleet intelligence is keeping me quite busy\n",
            "INPUT: to get them from somewhere else my shop's closed starfleet intelligence is keeping me quite\n",
            "PREDICTION: be back not somewhere else my shop's closed starfleet intelligence is keeping me quite busy\n",
            "===========================================================================\n",
            "INITIAL INPUT: boring\n",
            "GENERATED SEQUENCE: boring <END>\n",
            "\n",
            "INITIAL INPUT: boring\n",
            "GENERATED SEQUENCE: boring <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak boring\n",
            "GENERATED SEQUENCE: i am plain simple garak boring him commander deader in the core ye gods whatta meesa sayin' <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak boring\n",
            "GENERATED SEQUENCE: i am plain simple garak boring conversation there's something under the house a human with a fly head <END>\n",
            "\n",
            "===========================================================================\n",
            "\n",
            "Epoch 505 / 1001 Loss 0.4278\n",
            "===========================================================================\n",
            "TARGET: really understands it do they <END> what a waste of a morning that galipotan freighter\n",
            "INPUT: one really understands it do they <END> what a waste of a morning that galipotan\n",
            "PREDICTION: of understands it do they <END> what a waste of a morning that galipotan freighter\n",
            "---------------------------------------------------------------------------\n",
            "TARGET: really understands it do they <END> what a waste of a morning that galipotan freighter\n",
            "INPUT: one really understands it do they <END> what a waste of a morning that galipotan\n",
            "PREDICTION: of understands it do they <END> what a waste of a morning that galipotan freighter\n",
            "===========================================================================\n",
            "INITIAL INPUT: joey\n",
            "GENERATED SEQUENCE: joey i'm not into dead guys <END>\n",
            "\n",
            "INITIAL INPUT: joey\n",
            "GENERATED SEQUENCE: joey i'm not into dead guys <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak joey\n",
            "GENERATED SEQUENCE: i am plain simple garak joey the most important moment in your life you must know that your most cherished desire will come true here your sincerest wish the desire that\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak joey\n",
            "GENERATED SEQUENCE: i am plain simple garak joey i like my home <END>\n",
            "\n",
            "===========================================================================\n",
            "\n",
            "Epoch 506 / 1001 Loss 0.3537\n",
            "===========================================================================\n",
            "TARGET: quite serious believe me having someone try to kill you is no laughing matter <END>\n",
            "INPUT: i'm quite serious believe me having someone try to kill you is no laughing matter\n",
            "PREDICTION: afraid full believe me having someone try to kill you is no laughing matter <END>\n",
            "---------------------------------------------------------------------------\n",
            "TARGET: quite serious believe me having someone try to kill you is no laughing matter <END>\n",
            "INPUT: i'm quite serious believe me having someone try to kill you is no laughing matter\n",
            "PREDICTION: afraid full believe me having someone try to kill you is no laughing matter <END>\n",
            "===========================================================================\n",
            "INITIAL INPUT: kuwabara\n",
            "GENERATED SEQUENCE: kuwabara <END>\n",
            "\n",
            "INITIAL INPUT: kuwabara\n",
            "GENERATED SEQUENCE: kuwabara <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak kuwabara\n",
            "GENERATED SEQUENCE: i am plain simple garak kuwabara kuwabara <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak kuwabara\n",
            "GENERATED SEQUENCE: i am plain simple garak kuwabara <END>\n",
            "\n",
            "===========================================================================\n",
            "\n",
            "Epoch 507 / 1001 Loss 0.2783\n",
            "===========================================================================\n",
            "TARGET: <END> before i became a tailor i lived by a simple motto never allow sentiment\n",
            "INPUT: you <END> before i became a tailor i lived by a simple motto never allow\n",
            "PREDICTION: <END> i i became a tailor i lived by a simple motto never allow sentiment\n",
            "---------------------------------------------------------------------------\n",
            "TARGET: <END> before i became a tailor i lived by a simple motto never allow sentiment\n",
            "INPUT: you <END> before i became a tailor i lived by a simple motto never allow\n",
            "PREDICTION: <END> i i became a tailor i lived by a simple motto never allow sentiment\n",
            "===========================================================================\n",
            "INITIAL INPUT: haan\n",
            "GENERATED SEQUENCE: haan farishtey hote hain yes angels do exist <END>\n",
            "\n",
            "INITIAL INPUT: haan\n",
            "GENERATED SEQUENCE: haan farishtey hote hain yes angels do exist <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak haan\n",
            "GENERATED SEQUENCE: i am plain simple garak haan farishtey hote hain yes angels do exist <END>\n",
            "\n",
            "INITIAL INPUT: i am plain simple garak haan\n",
            "GENERATED SEQUENCE: i am plain simple garak haan farishtey hote hain yes angels do exist <END>\n",
            "\n",
            "===========================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}